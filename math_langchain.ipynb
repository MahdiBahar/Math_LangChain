{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161669/4093896791.py:4: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"phi4:latest\", base_url=\"http://127.0.0.1:11434\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Specify the remote server's URL\n",
    "llm = Ollama(model=\"phi4:latest\", base_url=\"http://127.0.0.1:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today? If you have any questions or need information, feel free to ask.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'سلام! بله، خیلی خوبم، صبر کنید چطوری می\\u200cشود؟ شما چطور هستید؟'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('سلام. خوبی؟')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "\n",
    "llm_math = LLMMathChain.from_llm(llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_math.prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_math.run(\"what is 13 raised to the .3432 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is 551368 divided by 82\u001b[32;1m\u001b[1;3mTo solve the problem of dividing 551368 by 82 using Python's `numexpr` library, we first need to translate the mathematical expression into a format that can be executed by `numexpr.evaluate`. Here’s how you can do it:\n",
      "\n",
      "```text\n",
      "551368 / 82\n",
      "```\n",
      "\n",
      "Now, let's evaluate this expression using `numexpr`:\n",
      "\n",
      "...numexpr.evaluate(\"551368 / 82\")...\n",
      "\n",
      "The output of running this code will give us the result of the division.\n",
      "\n",
      "Answer: 6722.0\n",
      "\n",
      "So, 551368 divided by 82 is 6722.0.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is 551368 divided by 82',\n",
       " 'answer': 'Answer:  6722.0\\n\\nSo, 551368 divided by 82 is 6722.0.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "example_query = \"What is 551368 divided by 82\"\n",
    "llm_math.invoke(example_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## understand which formula is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.router import LLMRouterChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from langchain.schema import BaseOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt templates for each formula chain\n",
    "house_price_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"This question asks about a house price. Apply Formula1: {question}\"\n",
    ")\n",
    "other_task_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"This question seems to be about another task. Apply Formula2: {question}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161669/207616203.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  house_price_chain = LLMChain(llm=llm, prompt=house_price_prompt)\n"
     ]
    }
   ],
   "source": [
    "# Create LLM chains for each formula\n",
    "house_price_chain = LLMChain(llm=llm, prompt=house_price_prompt)\n",
    "other_task_chain = LLMChain(llm=llm, prompt=other_task_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains.router import LLMRouterChain\n",
    "# from langchain.prompts import PromptTemplate\n",
    "\n",
    "# # Define a router prompt template that instructs the LLM on how to choose a chain.\n",
    "# router_prompt = PromptTemplate(\n",
    "#     input_variables=[\"question\"],\n",
    "#     template=(\n",
    "#         \"You are a routing assistant. Given the question below, \"\n",
    "#         \"if it is about house pricing, reply with 'house_price'. Otherwise, reply with 'other_task'.\\n\"\n",
    "#         \"Question: {question}\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Create the router chain using the supported factory method\n",
    "# router_chain = LLMRouterChain.from_llm(\n",
    "#     llm=llm,  # your LLM instance for routing\n",
    "#     prompt=router_prompt,\n",
    "#     destination_chains={\n",
    "#         \"house_price\": house_price_chain,\n",
    "#         \"other_task\": other_task_chain,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from langchain.schema import BaseOutputParser\n",
    "\n",
    "# class CustomRouterOutputParser(BaseOutputParser):\n",
    "#     def parse(self, text: str) -> dict:\n",
    "#         try:\n",
    "#             result = json.loads(text)\n",
    "#             # Ensure the required keys are present\n",
    "#             if \"destination\" not in result or \"next_inputs\" not in result:\n",
    "#                 raise ValueError(\"Output JSON is missing required keys.\")\n",
    "#             return result\n",
    "#         except json.JSONDecodeError as e:\n",
    "#             raise ValueError(f\"Could not parse output as JSON: {text}\") from e\n",
    "\n",
    "#     @property\n",
    "#     def _type(self) -> str:\n",
    "#         return \"custom_router_output_parser\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains.router.llm_router import LLMRouterChain\n",
    "# from langchain.prompts import PromptTemplate\n",
    "\n",
    "# # Instantiate your custom output parser\n",
    "# router_output_parser = CustomRouterOutputParser()\n",
    "\n",
    "# # Define the router prompt with the custom output parser attached\n",
    "# router_prompt = PromptTemplate(\n",
    "#     input_variables=[\"question\"],\n",
    "#     template=(\n",
    "#         \"You are a routing assistant. Given the question below, \"\n",
    "#         \"reply with a JSON string that includes the keys 'destination' and 'next_inputs'. \"\n",
    "#         \"If the question is about house pricing, set 'destination' to 'house_price'. \"\n",
    "#         \"Otherwise, set it to 'other_task'.\\n\"\n",
    "#         \"Question: {question}\"\n",
    "#     ),\n",
    "#     output_parser=router_output_parser\n",
    "# )\n",
    "\n",
    "# # Create the router chain using your custom prompt\n",
    "# router_chain = LLMRouterChain.from_llm(\n",
    "#     llm=llm,  # your LLM instance for routing\n",
    "#     prompt=router_prompt,\n",
    "#     destination_chains={\n",
    "#         \"house_price\": house_price_chain,\n",
    "#         \"other_task\": other_task_chain,\n",
    "#     }\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains.router.output_parser import RouterOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains.router.llm_router import LLMRouterChain\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.output_parsers import RouterOutputParser\n",
    "\n",
    "# # Create an output parser for the router chain\n",
    "# router_output_parser = RouterOutputParser()\n",
    "\n",
    "# # Define the router prompt and attach the output parser\n",
    "# router_prompt = PromptTemplate(\n",
    "#     input_variables=[\"question\"],\n",
    "#     template=(\n",
    "#         \"You are a routing assistant. Given the question below, \"\n",
    "#         \"reply with a JSON string that includes the keys 'destination' and 'next_inputs'. \"\n",
    "#         \"If the question is about house pricing, set 'destination' to 'house_price'. \"\n",
    "#         \"Otherwise, set it to 'other_task'.\\n\"\n",
    "#         \"Question: {question}\"\n",
    "#     ),\n",
    "#     output_parser=router_output_parser\n",
    "# )\n",
    "\n",
    "# # Create the router chain using the updated prompt\n",
    "# router_chain = LLMRouterChain.from_llm(\n",
    "#     llm=llm,  # your LLM instance for routing\n",
    "#     prompt=router_prompt,\n",
    "#     destination_chains={\n",
    "#         \"house_price\": house_price_chain,\n",
    "#         \"other_task\": other_task_chain,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a router chain that routes based on the question content\n",
    "# router_chain = LLMRouterChain.from_llm_and_prompts(\n",
    "#     llm=llm,  \n",
    "#     destination_chains={\n",
    "#         \"house_price\": house_price_chain,\n",
    "#         \"other_task\": other_task_chain,\n",
    "#     },\n",
    "#     # default_chain=default_chain  # if applicable \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_keys(d: dict) -> dict:\n",
    "    new_d = {}\n",
    "    for key, value in d.items():\n",
    "        # Strip whitespace and then remove surrounding quotes if present\n",
    "        new_key = key.strip()\n",
    "        if new_key.startswith('\"') and new_key.endswith('\"'):\n",
    "            new_key = new_key[1:-1]\n",
    "        if isinstance(value, dict):\n",
    "            new_d[new_key] = clean_keys(value)\n",
    "        else:\n",
    "            new_d[new_key] = value\n",
    "    return new_d\n",
    "\n",
    "class CustomRouterOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> dict:\n",
    "        # Extract the first JSON object from the text using regex\n",
    "        match = re.search(r\"(\\{.*\\})\", text, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(\"No JSON object found in text.\")\n",
    "        json_str = match.group(1)\n",
    "        try:\n",
    "            result = json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Error decoding JSON: {json_str}\") from e\n",
    "        # Clean the keys of the parsed JSON\n",
    "        result = clean_keys(result)\n",
    "        # Validate required keys\n",
    "        if \"destination\" not in result:\n",
    "            raise ValueError(\"Output JSON is missing the 'destination' key.\")\n",
    "        if \"next_inputs\" not in result:\n",
    "            raise ValueError(\"Output JSON is missing the 'next_inputs' key.\")\n",
    "        if not isinstance(result[\"next_inputs\"], dict):\n",
    "            raise ValueError(\"The 'next_inputs' key must be a dictionary.\")\n",
    "        if \"question\" not in result[\"next_inputs\"]:\n",
    "            raise ValueError(\"The 'next_inputs' dictionary must include the 'question' key.\")\n",
    "        return result\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"custom_router_output_parser\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "router_output_parser = CustomRouterOutputParser()\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=(\n",
    "        \"You are a routing assistant. Given the following question, decide which destination chain to use and return a valid JSON object with exactly two keys:\\n\"\n",
    "        \"1. destination: either \\\"house_price\\\" (if the question is about house pricing) or \\\"other_task\\\" for all other cases.\\n\"\n",
    "        \"2. next_inputs: a dictionary that includes the key \\\"question\\\" mapping to the original question text.\\n\"\n",
    "        \"For example, if the question is about house pricing, return:\\n\"\n",
    "        \"{{\\\"destination\\\": \\\"house_price\\\", \\\"next_inputs\\\": {{\\\"question\\\": \\\"What is the price of the house?\\\"}}}}\\n\"\n",
    "        \"Now, answer for the question: {question}\"\n",
    "    ),\n",
    "    output_parser=router_output_parser  # your custom parser\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(\n",
    "    llm=llm,  # your routing LLM instance\n",
    "    prompt=router_prompt,\n",
    "    destination_chains={\n",
    "        \"house_price\": house_price_chain,\n",
    "        \"other_task\": other_task_chain,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'please tell me about the price of the your house?', 'destination': 'house_price', 'next_inputs': {'question': 'please tell me about the price of your house?'}}\n"
     ]
    }
   ],
   "source": [
    "input_text = \"please tell me about the price of the your house?\"\n",
    "result = router_chain({\"question\": input_text})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.chains.router.llm_router import LLMRouterChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "# from langchain.llms import OpenAI  # Replace with your actual LLM (ollama, phi4, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Custom Output Parser Definition\n",
    "# -------------------------------\n",
    "def clean_keys(d: dict) -> dict:\n",
    "    \"\"\"Recursively clean dictionary keys by stripping whitespace and extra quotes.\"\"\"\n",
    "    new_d = {}\n",
    "    for key, value in d.items():\n",
    "        new_key = key.strip()\n",
    "        if new_key.startswith('\"') and new_key.endswith('\"'):\n",
    "            new_key = new_key[1:-1]\n",
    "        if isinstance(value, dict):\n",
    "            new_d[new_key] = clean_keys(value)\n",
    "        else:\n",
    "            new_d[new_key] = value\n",
    "    return new_d\n",
    "\n",
    "class CustomRouterOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> dict:\n",
    "        # Extract the first JSON object from the text\n",
    "        match = re.search(r\"(\\{.*\\})\", text, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(\"No JSON object found in text.\")\n",
    "        json_str = match.group(1)\n",
    "        try:\n",
    "            result = json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Error decoding JSON: {json_str}\") from e\n",
    "        # Clean the keys to remove any extra quotes\n",
    "        result = clean_keys(result)\n",
    "        # Validate required keys\n",
    "        if \"destination\" not in result:\n",
    "            raise ValueError(\"Output JSON is missing the 'destination' key.\")\n",
    "        if \"next_inputs\" not in result:\n",
    "            raise ValueError(\"Output JSON is missing the 'next_inputs' key.\")\n",
    "        if not isinstance(result[\"next_inputs\"], dict):\n",
    "            raise ValueError(\"The 'next_inputs' key must be a dictionary.\")\n",
    "        if \"question\" not in result[\"next_inputs\"]:\n",
    "            raise ValueError(\"The 'next_inputs' dictionary must include the 'question' key.\")\n",
    "        return result\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"custom_router_output_parser\"\n",
    "\n",
    "# Instantiate the custom output parser\n",
    "router_output_parser = CustomRouterOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Update: Define the Router Prompt (with escaped braces)\n",
    "# -------------------------------------------\n",
    "# CHANGED: The prompt now includes the \"loan_calculation\" destination.\n",
    "router_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=(\n",
    "        \"You are a routing assistant. Given the following question, decide which formula chain to use and return a valid JSON object with exactly two keys:\\n\"\n",
    "        \"1. destination: one of 'formula_1', 'formula_2', or 'loan_calculation'.\\n\"\n",
    "        \"   - Use 'formula_1' for questions about house pricing.\\n\"\n",
    "        \"   - Use 'loan_calculation' for questions about calculating remaining money for loans.\\n\"\n",
    "        \"   - Use 'formula_2' for all other tasks.\\n\"\n",
    "        \"2. next_inputs: a dictionary that includes the key 'question' mapping to the original question text.\\n\"\n",
    "        \"For example, if the question is 'What is the price of the house?', return:\\n\"\n",
    "        \"{{\\\"destination\\\": \\\"formula_1\\\", \\\"next_inputs\\\": {{\\\"question\\\": \\\"What is the price of the house?\\\"}}}}\\n\"\n",
    "        \"Now, answer for the question: {question}\"\n",
    "    ),\n",
    "    output_parser=router_output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Create Dummy Formula Chains for Each Task/Formula\n",
    "# --------------------------------------------------------\n",
    "# llm = OpenAI(temperature=0)  # Replace with your preferred LLM instance\n",
    "\n",
    "# Formula 1: House Pricing (unchanged)\n",
    "formula_1_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Formula 1 (House Pricing): Given the question: {question}, compute the house price using the relevant pricing formula.\"\n",
    ")\n",
    "formula_1_chain = LLMChain(llm=llm, prompt=formula_1_prompt, verbose=True)\n",
    "\n",
    "# Formula 2: Generic Task (unchanged)\n",
    "formula_2_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Formula 2: Given the question: {question}, compute the answer using a generic approach.\"\n",
    ")\n",
    "formula_2_chain = LLMChain(llm=llm, prompt=formula_2_prompt, verbose=True)\n",
    "\n",
    "# NEW: Loan Calculation Chain\n",
    "# This chain is used when the question is about calculating how much money to pay for loans.\n",
    "loan_calculation_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=(\n",
    "        \"Loan Calculation Expert: For the question: {question}\\n\"\n",
    "        \"Use the formula: total_amount - (number_of_paid_loans * amount_per_loan)\\n\"\n",
    "        \"to calculate the amount of money required to pay all the loans. \\n\"\n",
    "        \"Here, total_amount is the total money received by the user, \"\n",
    "        \"number_of_paid_loans is the number of loans paid, and \"\n",
    "        \"amount_per_loan is the cost of each paid loan. \\n\"\n",
    "        \"Explain the formula and show an example calculation.\"\n",
    "    )\n",
    ")\n",
    "loan_calculation_chain = LLMChain(llm=llm, prompt=loan_calculation_prompt, verbose=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Update: Create the Router Chain with the Three Destination Chains\n",
    "# ---------------------------------------------------------------\n",
    "# CHANGED: The destination_chains dictionary now includes the key \"loan_calculation\"\n",
    "router_chain = LLMRouterChain.from_llm(\n",
    "    llm=llm,\n",
    "    prompt=router_prompt,\n",
    "    destination_chains={\n",
    "        \"formula_1\": formula_1_chain,\n",
    "        \"formula_2\": formula_2_chain,\n",
    "        \"loan_calculation\": loan_calculation_chain,  # NEW destination\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router output: {'question': 'How much money should I pay to pay all my loans to the bank?', 'destination': 'loan_calculation', 'next_inputs': {'question': 'How much money should I pay to pay all my loans to the bank?'}}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mLoan Calculation Expert: For the question: How much money should I pay to pay all my loans to the bank?\n",
      "Use the formula: total_amount - (number_of_paid_loans * amount_per_loan)\n",
      "to calculate the amount of money required to pay all the loans. \n",
      "Here, total_amount is the total money received by the user, number_of_paid_loans is the number of loans paid, and amount_per_loan is the cost of each paid loan. \n",
      "Explain the formula and show an example calculation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final result from 'loan_calculation': {'question': 'How much money should I pay to pay all my loans to the bank?', 'text': \"### Explanation of the Formula\\n\\nThe formula used to calculate how much money you should pay to settle all your loans is:\\n\\n\\\\[ \\\\text{Amount Required} = \\\\text{total\\\\_amount} - (\\\\text{number\\\\_of\\\\_paid\\\\_loans} \\\\times \\\\text{amount\\\\_per\\\\_loan}) \\\\]\\n\\nHere's a breakdown of each component in the formula:\\n\\n- **Total Amount**: This represents the total amount of money you currently have or plan to use towards paying off your loans.\\n\\n- **Number of Paid Loans**: This is the number of loans that you have already paid off.\\n\\n- **Amount Per Loan**: This refers to the cost required to pay off each individual loan. \\n\\nThe formula essentially calculates how much more money you need by subtracting the total amount you've already spent on paying off some loans (calculated as `number_of_paid_loans * amount_per_loan`) from your total available funds (`total_amount`).\\n\\n### Example Calculation\\n\\nLet's consider an example:\\n\\n- **Total Amount**: $50,000 (the total money you have)\\n- **Number of Paid Loans**: 5 (you've already paid off 5 loans)\\n- **Amount Per Loan**: $4,000 (each loan costs $4,000)\\n\\nUsing the formula:\\n\\n\\\\[ \\\\text{Amount Required} = 50,000 - (5 \\\\times 4,000) \\\\]\\n\\nFirst, calculate the total cost of the paid loans:\\n\\n\\\\[ 5 \\\\times 4,000 = 20,000 \\\\]\\n\\nNow, subtract this from your total amount:\\n\\n\\\\[ 50,000 - 20,000 = 30,000 \\\\]\\n\\nSo, you have $30,000 remaining to pay off any additional loans. If there are no more outstanding loans or if this amount is sufficient for future payments, that's the money left after settling the paid loans.\\n\\nIf you had more loans to settle with specific costs, you would need to consider those in your budgeting plan using this formula as a starting point.\"}\n"
     ]
    }
   ],
   "source": [
    "# Create the mapping for destination chains (separate from the router chain)\n",
    "destination_chains = {\n",
    "    \"formula_1\": formula_1_chain,\n",
    "    \"formula_2\": formula_2_chain,\n",
    "    \"loan_calculation\": loan_calculation_chain,\n",
    "}\n",
    "\n",
    "# -------------------------------------------\n",
    "# Example Usage: A Loan Calculation Question\n",
    "# -------------------------------------------\n",
    "input_text = \"How much money should I pay to pay all my loans to the bank?\"\n",
    "# input_text = \"چه مقدار پول باید بدم به بانک تا وام من تسویه بشه؟\"\n",
    "# First, use the router chain to determine which formula chain to use.\n",
    "router_result = router_chain({\"question\": input_text})\n",
    "print(\"Router output:\", router_result)\n",
    "\n",
    "# Extract destination and next_inputs from the router output.\n",
    "destination = router_result[\"destination\"]\n",
    "next_inputs = router_result[\"next_inputs\"]\n",
    "\n",
    "# Use our separate mapping to call the selected destination chain.\n",
    "if destination in destination_chains:\n",
    "    final_result = destination_chains[destination](next_inputs)\n",
    "    print(f\"Final result from '{destination}':\", final_result)\n",
    "else:\n",
    "    print(\"Destination not found:\", destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
